---
title: EZVals
description: The evals framework your coding agent wants
---

<img
  className="block dark:hidden"
  src="/assets/hero-light.svg"
  alt="EZVals"
/>
<img
  className="hidden dark:block"
  src="/assets/hero-dark.svg"
  alt="EZVals"
/>

EZVals is an evaluation framework for testing LLMs and Agents

What makes EZVals special is that its built to be used by your coding agent. Your agent writes evals, runs them, analyzes results, and iterates while you monitor the situation from the Dashboard.

<CardGroup cols={2}>
  <Card title="Agent-First" icon="robot">
    Full CLI that mirrors every UI action. Built-in [skill](/guides/agent-skill) gives your agent eval-specific guidance.
  </Card>
  <Card title="Local Dashboard" icon="chart-mixed">
    [Compare runs](/guides/web-ui), annotate, and export from a local web UI.
  </Card>
  <Card title="Flexible" icon="sliders">
    Quick smoke tests or deep multi-model comparisons. [Pytest-style assertions](/core-concepts/scoring), clean code.
  </Card>
  <Card title="Local-Only" icon="laptop-code">
    Code, data, and results live in your repo. No external platforms or auth.
  </Card>
</CardGroup>

## Get Started

Install the EZVals skill for your coding agent:

```bash
npx skills add camronh/evals-skill
```

Then prompt your agent:

<CodeGroup>

```text Compare
Compare Opus 4.6 vs GPT-5.3 on answer correctness. Show me the comparison.
```

```text Evaluate
Help me evaluate hallucinations in my RAG agent @agent.py
```

```text Error Analysis
Run error analysis on the last eval run @.ezvals/sessions/rag-tests/baseline_a1b2c3d4.json
```


</CodeGroup>

The agent writes the evals, runs them, and reports back with results. For the comparison example, that looks something like:

```markdown
I ran both models against your 50-question correctness dataset.

| Model    | Correctness | Avg Latency |
|----------|-------------|-------------|
| Opus 4.6 | 94%         | 1.2s        |
| GPT-5.3  | 87%         | 0.8s        |

Opus scores 7% higher on correctness but is ~50% slower.

Full comparison: http://127.0.0.1:8000/?compare_run_id=a1b2...&compare_run_id=c3d4...
```

<img
  className="block dark:hidden"
  src="/assets/comparison-light.png"
  alt="EZVals Comparison View"
/>
<img
  className="hidden dark:block"
  src="/assets/comparison-dark.png"
  alt="EZVals Comparison View"
/>

Results can be exported as JSON, CSV, Markdown, or PNG from the dashboard or CLI.

<Card title="Setup Details" icon="gear" href="/setup">
  Install the library directly, configure your project, and learn how EZVals works under the hood.
</Card>
